{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Tune\n",
    "In this notebook, we perform a parameter search for the following methods. \n",
    "We also optionally record the test results\n",
    "to an Excel sheet and pickle file for later analysis.\n",
    "\n",
    "| Method      | Parameters |\n",
    "|:-           | :-         |\n",
    "|TBAC         | Aggregation, PC siginificant value(only in IBM)|\n",
    "| MonitorRank | Aggregation, Test round, Backward edge coefficient, PC siginificant value(only in IBM)|\n",
    "| CloudRanger | Aggregation, PC siginificant value, Test round, Second order mixture coefficient, Backward edge coefficient |\n",
    "| NetMedic    | History range start, History len, Current range start, current len, Bin size |\n",
    "| DyCause | Aggregation, Start time(optional), Before length, After length, Interval step, Granger siginificant value, Lag, Adaptive threshold ratio, Backtrace max path length, Prob mean method, Topk path number, Number of selected node |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from main_cloud_ranger import test_cloud_ranger\n",
    "from main_dycause import test_dycause as test_granger_extend\n",
    "from main_tbac import test_tbac\n",
    "from main_monitor_rank import test_monitor_rank\n",
    "\n",
    "# from main_facgraph import test_facgraph\n",
    "from main_netmedic import test_netmedic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select dataset\n",
    "For the IBM incident dataset, the running time for these methods is quite long. \n",
    "\n",
    "For example, for CloudRanger, it may take more than 1 day. \n",
    "\n",
    "If you are not intended to reproduce the exact results, we don't recommand trying them.\n",
    "\n",
    "The workbook `ComparisonExpLog.xlsx` and the sheets `Parameter Analysis(IBM)`, `Comparison Experiments(Pymicro)` must be created before running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!! IBM Micro Service Test Suite !!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "workbook_name = 'ComparisonExpLog.xlsx'\n",
    "# sheet_name = 'Comparison Experiments(Pymicro)'\n",
    "sheet_name = 'Parameter Analysis(IBM)'\n",
    "\n",
    "# pymicro test suite\n",
    "# print(\"\\n{:!^80}\\n\".format(\" Pymicro Test Suite \"))\n",
    "# dataset_name = 'pymicro'\n",
    "# entry_point_list = [16]\n",
    "# true_root_cause = [1]\n",
    "\n",
    "# ibm_micro_service test suite\n",
    "print(\"\\n{:!^80}\\n\".format(\" IBM Micro Service Test Suite \"))\n",
    "dataset_name = 'ibm_micro_service'\n",
    "entry_point_list = [14]\n",
    "true_root_cause = [6, 28, 30, 31]\n",
    "# true_root_cause_1 = [28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBAC Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "wb = load_workbook(workbook_name)\n",
    "sheet = wb[sheet_name]\n",
    "\n",
    "row = 3\n",
    "for ela in range(1, 21):\n",
    "    for alpha in [0.05, 0.1, 0.2]:\n",
    "        prks, acc = test_tbac(\n",
    "            dataset_name,\n",
    "            ela=ela, \n",
    "            alpha=alpha,\n",
    "            frontend=entry_point_list[0], \n",
    "            true_root_cause=true_root_cause,\n",
    "            verbose=verbose)\n",
    "        sheet.cell(row=row, column=1, value=ela)\n",
    "        sheet.cell(row=row, column=2, value=alpha)\n",
    "        for i, prk in enumerate(prks):\n",
    "            sheet.cell(row=row, column=3+i, value=prk)\n",
    "        sheet.cell(row=row, column=8, value=np.mean(prks))\n",
    "        sheet.cell(row=row, column=9, value=acc)\n",
    "        row += 1\n",
    "wb.save(workbook_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MonitorRank Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "results = []\n",
    "for ela in range(1, 21):\n",
    "    for testround in [5]:\n",
    "        for rho in [0.2, 0.4, 0.6, 0.8]:\n",
    "            prks, acc = test_monitor_rank(\n",
    "                dataset_name,\n",
    "                ela=ela,\n",
    "                testrun_round=testround,\n",
    "                frontend=entry_point_list[0],\n",
    "                true_root_cause=true_root_cause,\n",
    "                rho=rho,\n",
    "                save_data_fig=False,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "            results.append({'ela': ela, 'testround': testround, 'rho': rho, 'prks': prks, 'acc': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(workbook_name)\n",
    "sheet = wb[sheet_name]\n",
    "row = 3\n",
    "index = 0\n",
    "for ela in range(1, 21):\n",
    "    for testround in [5]:\n",
    "        for rho in [0.2, 0.4, 0.6, 0.8]:\n",
    "            result = results[index]\n",
    "            sheet.cell(row=row, column=12, value=result['ela'])\n",
    "            sheet.cell(row=row, column=13, value=result['testround'])\n",
    "            sheet.cell(row=row, column=14, value=result['rho'])\n",
    "            for i, prk in enumerate(result['prks']):\n",
    "                sheet.cell(row=row, column=15+i, value=prk)\n",
    "            sheet.cell(row=row, column=20, value=np.mean(result['prks']))\n",
    "            sheet.cell(row=row, column=21, value=result['acc'])\n",
    "            row += 1\n",
    "            index += 1\n",
    "wb.save(workbook_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CloudRanger tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "results = []\n",
    "pbar = tqdm(total=20*5*3*4, ascii=True)\n",
    "for ela in range(1, 21):\n",
    "    for alpha in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        for testround in [5]:\n",
    "            for beta in [0.1, 0.5, 0.9]:\n",
    "                for rho in [0.2, 0.4, 0.6, 0.8]:\n",
    "                    prks, acc = test_cloud_ranger(\n",
    "                        data_source=dataset_name,\n",
    "                        pc_aggregate=ela,\n",
    "                        pc_alpha=alpha,\n",
    "                        testrun_round=testround,\n",
    "                        frontend=entry_point_list[0],\n",
    "                        true_root_cause=true_root_cause,\n",
    "                        beta=beta,\n",
    "                        rho=rho,\n",
    "                        save_data_fig=False,\n",
    "                        verbose=verbose,\n",
    "                    )\n",
    "                    results.append({'ela': ela, 'alpha': alpha, 'testround': testround, \n",
    "                                    'beta': beta, 'rho': rho, 'prks': prks, 'acc': acc})\n",
    "                    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the external result pickle obtained from `cloudranger_params_tune.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('cloudranger_parameter_tune_ibm.pkl', 'rb') as f:\n",
    "#     results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(workbook_name)\n",
    "sheet = wb[sheet_name]\n",
    "row = 3\n",
    "column_base = 24\n",
    "for result in results:\n",
    "    sheet.cell(row=row, column=column_base, value=result['ela'])\n",
    "    sheet.cell(row=row, column=column_base+1, value=result['alpha'])\n",
    "    sheet.cell(row=row, column=column_base+2, value=result['testround'])\n",
    "    sheet.cell(row=row, column=column_base+3, value=result['beta'])\n",
    "    sheet.cell(row=row, column=column_base+4, value=result['rho'])\n",
    "    for i, prk in enumerate(result['prks']):\n",
    "        sheet.cell(row=row, column=column_base+5+i, value=prk)\n",
    "    sheet.cell(row=row, column=column_base+10, value=np.mean(result['prks']))\n",
    "    sheet.cell(row=row, column=column_base+11, value=result['acc'])\n",
    "    row += 1\n",
    "wb.save(workbook_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetMedic tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "results = []\n",
    "pbar = tqdm(total=3*2*2*2*3, ascii=True)\n",
    "# for hist_start in [0, 200, 400]:\n",
    "#     for hist_len in [200, 400]:\n",
    "#         for current_start in [800, 1000]:\n",
    "#             for current_len in [200, 400]:\n",
    "#                 for bin_size in [50, 100, 150]:\n",
    "for hist_start in [0, 2000, 4000]:\n",
    "    for hist_len in [200, 400]:\n",
    "        for current_start in [4600, 5000]:\n",
    "            for current_len in [200, 400]:\n",
    "                for bin_size in [10, 30, 50]:\n",
    "                    prks, acc = test_netmedic(\n",
    "                        data_source=dataset_name,\n",
    "                        history_range=(hist_start, hist_start+hist_len),\n",
    "                        current_range=(current_start, current_start+current_len),\n",
    "                        bin_size=bin_size,\n",
    "                        affected_node=entry_point_list[0],\n",
    "                        true_root_cause=true_root_cause,\n",
    "                        verbose=verbose,\n",
    "                        disable_print=True\n",
    "                    )\n",
    "                    results.append({'hist_start': hist_start, 'hist_len': hist_len, \n",
    "                                    'current_start': current_start, 'current_len': current_len,\n",
    "                                    'bin_size': bin_size, \n",
    "                                    'prks': prks, 'acc': acc})\n",
    "                    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(workbook_name)\n",
    "sheet = wb[sheet_name]\n",
    "row = 3\n",
    "column_base = 38\n",
    "for result in results:\n",
    "    sheet.cell(row=row, column=column_base, value=result['hist_start'])\n",
    "    sheet.cell(row=row, column=column_base+1, value=result['hist_len'])\n",
    "    sheet.cell(row=row, column=column_base+2, value=result['current_start'])\n",
    "    sheet.cell(row=row, column=column_base+3, value=result['current_len'])\n",
    "    sheet.cell(row=row, column=column_base+4, value=result['bin_size'])\n",
    "    for i, prk in enumerate(result['prks']):\n",
    "        sheet.cell(row=row, column=column_base+5+i, value=prk)\n",
    "    sheet.cell(row=row, column=column_base+10, value=np.mean(result['prks']))\n",
    "    sheet.cell(row=row, column=column_base+11, value=result['acc'])\n",
    "    row += 1\n",
    "wb.save(workbook_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DyCause tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2430"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * (4 * 4 -1 )* 3 * 1 * 3 * 3 * 1 * 2 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "verbose = False\n",
    "# wb = load_workbook('ComparisonExpLog-2020,04,27.xlsx')\n",
    "# sheet = wb['Comparison Experiments']\n",
    "\n",
    "result_list = []\n",
    "param_list = []\n",
    "\n",
    "i = 0\n",
    "for aggre_delta in range(1, 2):\n",
    "    for before_length in [0, 100, 200, 300]:\n",
    "        for after_length in [0, 100, 200, 300]:\n",
    "            for step in [50, 60, 70]:\n",
    "                for sig_value in [0.1]:\n",
    "                    for lag in [5, 10, 15]:\n",
    "                        for thres in [0.5, 0.7, 0.9]:\n",
    "                            for max_path_length in [33]:\n",
    "                                for mean_method in ['arithmetic', 'geometric', 'harmonic'][2:3]:\n",
    "                                    for topk_path in [50, 150]:\n",
    "                                        for num_sel_node in range(1, 4):\n",
    "                                            if before_length != 0 or after_length != 0:\n",
    "                                                param_list.append({\n",
    "                                                    'ela': aggre_delta,\n",
    "                                                    'bef': before_length, \n",
    "                                                    'aft': after_length, \n",
    "                                                    'step': step, \n",
    "                                                    'sig_value': sig_value,\n",
    "                                                    'lag': lag, \n",
    "                                                    'thres': thres, \n",
    "                                                    'max_path_length': max_path_length,\n",
    "                                                    'mean_method': mean_method,\n",
    "                                                    'topk_path': topk_path,\n",
    "                                                    'num_sel_node': num_sel_node,\n",
    "                                                })\n",
    "\n",
    "\n",
    "pbar = tqdm(total=len(param_list), ascii=True)\n",
    "for i, params_dict in enumerate(param_list):\n",
    "    if i<162:\n",
    "        continue\n",
    "    prks, acc = test_granger_extend(\n",
    "        # Data params\n",
    "        data_source=dataset_name,\n",
    "        aggre_delta=params_dict['ela'],\n",
    "        start_time=4653,\n",
    "        before_length=params_dict['bef'],\n",
    "        after_length=params_dict['aft'],\n",
    "        # Granger interval based graph construction params\n",
    "        step=params_dict['step'],\n",
    "        significant_thres=params_dict['sig_value'],\n",
    "        lag=params_dict['lag'],\n",
    "        auto_threshold_ratio = params_dict['thres'],\n",
    "        # Root cause analysis params\n",
    "        max_path_length=params_dict['max_path_length'],\n",
    "        mean_method=params_dict['mean_method'],\n",
    "        topk_path = params_dict['topk_path'],\n",
    "        num_sel_node = params_dict['num_sel_node'],\n",
    "        testrun_round=1,\n",
    "        frontend=entry_point_list[0],\n",
    "        true_root_cause=true_root_cause,\n",
    "        # Debug params\n",
    "        plot_figures=False,\n",
    "        verbose=True,\n",
    "        disable_print=False\n",
    "    )\n",
    "    pbar.update(1)\n",
    "    result_list.append(params_dict)\n",
    "    result_list[-1]['prks'] = prks\n",
    "    result_list[-1]['acc'] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the external result pickle obtained from `dycause_params_tune.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('granger_extend_parameter_tune_ibm.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ela': 6,\n",
       " 'bef': 0,\n",
       " 'aft': 100,\n",
       " 'step': 50,\n",
       " 'sig_value': 0.1,\n",
       " 'lag': 5,\n",
       " 'thres': 0.7,\n",
       " 'max_path_length': None,\n",
       " 'mean_method': 'harmonic',\n",
       " 'topk_path': 150,\n",
       " 'num_sel_node': 3,\n",
       " 'prks': [0.0, 0.5, 0.3333333333333333, 0.25, 0.25],\n",
       " 'acc': 0.25}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average the performance for  each aggregation delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_key_dict = {}\n",
    "for result in results:\n",
    "    ela = result['ela']\n",
    "    prks = result['prks']\n",
    "    acc = result['acc']\n",
    "    if ela in result_key_dict:\n",
    "        result_key_dict[ela]['prks'].append(prks)\n",
    "        result_key_dict[ela]['prk@avg'].append(np.mean(prks))\n",
    "        result_key_dict[ela]['acc'].append(acc)\n",
    "        result_key_dict[ela]['others'].append(result)\n",
    "    else:\n",
    "        result_key_dict[ela] = {}\n",
    "        result_key_dict[ela]['prks'] = [prks]\n",
    "        result_key_dict[ela]['prk@avg'] = [np.mean(prks)]\n",
    "        result_key_dict[ela]['acc'] = [acc]    \n",
    "        result_key_dict[ela]['others'] = [result]\n",
    "acc_dict = {}\n",
    "for key, d in result_key_dict.items():\n",
    "    acc_dict[key] = (\n",
    "        d['prk@avg'],\n",
    "        np.max(d['acc']),\n",
    "        np.argmax(d['acc'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.99 PR@k:  1.00,1.00,0.67,0.75,1.00 {'ela': 6, 'bef': 100, 'aft': 100, 'step': 50, 'sig_value': 0.1, 'lag': 5, 'thres': 0.7, 'max_path_length': None, 'mean_method': 'harmonic', 'topk_path': 150, 'num_sel_node': 1, 'prks': [1.0, 1.0, 0.6666666666666666, 0.75, 1.0], 'acc': 0.9924242424242424}\n",
      "Acc: 0.99 PR@k:  1.00,1.00,0.67,0.75,1.00 {'ela': 7, 'bef': 100, 'aft': 100, 'step': 70, 'sig_value': 0.1, 'lag': 5, 'thres': 0.7, 'max_path_length': None, 'mean_method': 'harmonic', 'topk_path': 150, 'num_sel_node': 3, 'prks': [1.0, 1.0, 0.6666666666666666, 0.75, 1.0], 'acc': 0.9924242424242424}\n",
      "Acc: 0.99 PR@k:  1.00,1.00,0.67,0.75,1.00 {'ela': 8, 'bef': 100, 'aft': 100, 'step': 60, 'sig_value': 0.1, 'lag': 5, 'thres': 0.5, 'max_path_length': None, 'mean_method': 'harmonic', 'topk_path': 150, 'num_sel_node': 1, 'prks': [1.0, 1.0, 0.6666666666666666, 0.75, 1.0], 'acc': 0.9924242424242424}\n",
      "Acc: 0.99 PR@k:  0.00,0.50,0.67,0.75,1.00 {'ela': 9, 'bef': 100, 'aft': 0, 'step': 50, 'sig_value': 0.1, 'lag': 5, 'thres': 0.5, 'max_path_length': None, 'mean_method': 'harmonic', 'topk_path': 150, 'num_sel_node': 1, 'prks': [0.0, 0.5, 0.6666666666666666, 0.75, 1.0], 'acc': 0.9924242424242424}\n",
      "Acc: 0.99 PR@k:  1.00,1.00,0.67,0.75,1.00 {'ela': 10, 'bef': 100, 'aft': 0, 'step': 50, 'sig_value': 0.1, 'lag': 5, 'thres': 0.9, 'max_path_length': None, 'mean_method': 'harmonic', 'topk_path': 150, 'num_sel_node': 3, 'prks': [1.0, 1.0, 0.6666666666666666, 0.75, 1.0], 'acc': 0.9924242424242424}\n"
     ]
    }
   ],
   "source": [
    "for k in acc_dict:\n",
    "    print('Acc: {:0.2f}'.format(acc_dict[k][1]), 'PR@k: ', ','.join(['{:0.2f}'.format(_) for _ in result_key_dict[k]['prks'][acc_dict[k][2]]]),end=' ')\n",
    "    print(result_key_dict[k]['others'][acc_dict[k][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(workbook_name)\n",
    "# sheet = wb['Comparison Experiments(IBM)']\n",
    "sheet = wb['Parameter Analysis(IBM)']\n",
    "row = 19\n",
    "column_base = 1\n",
    "for result in results:\n",
    "# for result in result_list:\n",
    "    if result['acc'] <= 0:\n",
    "        continue\n",
    "    sheet.cell(row=row, column=column_base, value=result['ela'])\n",
    "    sheet.cell(row=row, column=column_base+1, value=4653)\n",
    "    sheet.cell(row=row, column=column_base+2, value=result['bef'])\n",
    "    sheet.cell(row=row, column=column_base+3, value=result['aft'])\n",
    "    sheet.cell(row=row, column=column_base+4, value=result['step'])\n",
    "    sheet.cell(row=row, column=column_base+5, value=result['sig_value'])\n",
    "    sheet.cell(row=row, column=column_base+6, value=result['lag'])\n",
    "    sheet.cell(row=row, column=column_base+7, value=result['thres'])\n",
    "    sheet.cell(row=row, column=column_base+8, value=result['max_path_length'])\n",
    "    sheet.cell(row=row, column=column_base+9, value=result['mean_method'])\n",
    "    sheet.cell(row=row, column=column_base+10, value=result['topk_path'])\n",
    "    sheet.cell(row=row, column=column_base+11, value=result['num_sel_node'])\n",
    "    for i, prk in enumerate(result['prks']):\n",
    "        sheet.cell(row=row, column=column_base+12+i, value=prk)\n",
    "    sheet.cell(row=row, column=column_base+17, value=np.mean(result['prks']))\n",
    "    sheet.cell(row=row, column=column_base+18, value=result['acc'])\n",
    "    row += 1\n",
    "wb.save(workbook_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DyCause parameter analysis 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                 | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|########1                                                | 1/7 [00:02<00:13,  2.29s/it]\u001b[A\n",
      " 29%|################2                                        | 2/7 [00:04<00:11,  2.27s/it]\u001b[A\n",
      " 43%|########################4                                | 3/7 [00:07<00:10,  2.51s/it]\u001b[A\n",
      " 57%|################################5                        | 4/7 [00:10<00:08,  2.77s/it]\u001b[A\n",
      " 71%|########################################7                | 5/7 [00:13<00:05,  2.73s/it]\u001b[A\n",
      " 86%|################################################8        | 6/7 [00:16<00:02,  2.80s/it]\u001b[A\n",
      "100%|#########################################################| 7/7 [00:20<00:00,  3.06s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "# wb = load_workbook('ComparisonExpLog-2020,04,27.xlsx')\n",
    "# sheet = wb['Comparison Experiments']\n",
    "\n",
    "result_list = []\n",
    "param_list = []\n",
    "\n",
    "i = 0\n",
    "for aggre_delta in range(1, 2):\n",
    "    for before_length in range(0, 350, 50):\n",
    "        for after_length in [200]:\n",
    "            for step in [70]:\n",
    "                for sig_value in [0.1]:\n",
    "                    for lag in [5]:\n",
    "                        for thres in [0.7]:\n",
    "                            for max_path_length in [None]:\n",
    "                                for mean_method in ['arithmetic', 'geometric', 'harmonic'][2:3]:\n",
    "                                    for topk_path in [50]:\n",
    "                                        for num_sel_node in [3]:\n",
    "                                            if before_length != 0 or after_length != 0:\n",
    "                                                param_list.append({\n",
    "                                                    'ela': aggre_delta,\n",
    "                                                    'bef': before_length, \n",
    "                                                    'aft': after_length, \n",
    "                                                    'step': step, \n",
    "                                                    'sig_value': sig_value,\n",
    "                                                    'lag': lag, \n",
    "                                                    'thres': thres, \n",
    "                                                    'max_path_length': max_path_length,\n",
    "                                                    'mean_method': mean_method,\n",
    "                                                    'topk_path': topk_path,\n",
    "                                                    'num_sel_node': num_sel_node,\n",
    "                                                })\n",
    "\n",
    "\n",
    "pbar = tqdm(total=len(param_list), ascii=True)\n",
    "for i, params_dict in enumerate(param_list):\n",
    "#     if i<162:\n",
    "#         continue\n",
    "    prks, acc = test_granger_extend(\n",
    "        # Data params\n",
    "        data_source=dataset_name,\n",
    "        aggre_delta=params_dict['ela'],\n",
    "        start_time=4653,\n",
    "        before_length=params_dict['bef'],\n",
    "        after_length=params_dict['aft'],\n",
    "        # Granger interval based graph construction params\n",
    "        step=params_dict['step'],\n",
    "        significant_thres=params_dict['sig_value'],\n",
    "        lag=params_dict['lag'],\n",
    "        auto_threshold_ratio = params_dict['thres'],\n",
    "        # Root cause analysis params\n",
    "        max_path_length=params_dict['max_path_length'],\n",
    "        mean_method=params_dict['mean_method'],\n",
    "        topk_path = params_dict['topk_path'],\n",
    "        num_sel_node = params_dict['num_sel_node'],\n",
    "        testrun_round=1,\n",
    "        frontend=entry_point_list[0],\n",
    "        true_root_cause=true_root_cause,\n",
    "        # Debug params\n",
    "        plot_figures=False,\n",
    "        verbose=False,\n",
    "        disable_print=True\n",
    "    )\n",
    "    pbar.update(1)\n",
    "    result_list.append(params_dict)\n",
    "    result_list[-1]['prks'] = prks\n",
    "    result_list[-1]['acc'] = acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
